# vLLM Deployment with Load Test

## ğŸš€ Deployment Steps

1. **Build Docker Image:**
```bash
docker compose up --build -d
```

2. **Run Load Test (Small):**
```bash
k6 run k6-test-small.js
```

3. **Run Load Test (Medium):**
```bash
k6 run k6-test-medium.js
```

4. **Run Load Test (Large):**
```bash
k6 run k6-test-large.js
```

---

## ğŸ“Š Load Test Scenarios

| Test Type | Peak Users | Hold Time | Latency Threshold |
|-----------|------------|-----------|-------------------|
| Small     | 50         | 20s       | 500ms             |
| Medium    | 500        | 1m        | 700ms             |
| Large     | 5000       | 5m        | 1000ms            |

---

## ğŸ“¦ Model Size Reference

| Quant             | Bits  | File Size     | Est. RAM Need |
|-------------------|-------|---------------|----------------|
| Q2_K              | 2â€‘bit | 3.08â€¯GB       | ~5.6â€¯GB        |
| Q3_K_*            | 3â€‘bit | 3.16â€“3.82â€¯GB  | ~5.6â€“6.3â€¯GB    |
| Q4_0 / Q4_K_*     | 4â€‘bit | 4.11â€“4.37â€¯GB  | ~6.6â€“6.9â€¯GB    |
| Q5_*              | 5â€‘bit | ~5.0â€“5.13â€¯GB  | ~7.5â€“7.6â€¯GB    |
| Q6_K              | 6â€‘bit | 5.94â€¯GB       | ~8.4â€¯GB        |
| Q8_0              | 8â€‘bit | 7.7â€¯GB        | ~10.2â€¯GB       |

---

## ğŸ” Model Benchmark Comparison

| Model Name            | Parameters | VRAM (Q4) | Tokens/s (vLLM) | Notes                     |
|----------------------|------------|-----------|-----------------|---------------------------|
| Mistral 7B Instruct   | 7B         | ~7 GB     | ~20-40 t/s      | Balanced accuracy & speed |
| Mistral 3B Instruct   | 3B         | ~4.5 GB   | ~50-80 t/s      | Faster, smaller version   |
| Gemma 2B              | 2B         | ~3.5 GB   | ~70-100 t/s     | Lightweight, efficient    |
| TinyLlama 1.1B        | 1.1B       | ~2.8 GB   | ~100-150 t/s    | Super fast, low memory    |
| Phi-2                 | 2.7B       | ~5 GB     | ~50-80 t/s      | Lightweight, good accuracy|
| Qwen 1.5B             | 1.5B       | ~3 GB     | ~80-120 t/s     | Multilingual support      |

---

## âœ… Requirements
- Docker
- GPU (minimum 24GB VRAM recommended)
- k6 load testing tool ([install here](https://k6.io/docs/getting-started/installation/))

---

## ğŸ”§ Notes
- Pastikan Docker dan GPU driver berjalan dengan baik.
- Pastikan port `8000` terbuka dan bisa diakses.
- Bisa di-scale dengan `docker compose up --scale vllm=4` untuk multi-replica.
